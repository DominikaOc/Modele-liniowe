---
title: "Modele liniowe, Lista 4"
author: "Dominika Ochalik"
date: "2024-01-05"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
toc-title: "SPIS TREŚCI"
---

\newpage
# Wstęp

Lista 4 rozpoczyna analizę regresji liniowej z więcej niż jedną zmienną objaśniającą, tzn. modele postaci:
$$Y = \beta_0 + \beta_1 X_1 + ... + \beta_n X_n + \epsilon$$
Jest to przydatne uogólnienie dotychczas rozważanego modelu regresji liniowej, ponieważ często badana wielkość $Y$ zależy od więcej niż jednego czynnika.

Zadania na liście skupiają się także wokół analizy, czy dodanie do równania kolejnej zmiennej objaśniającej sprawi, że model staje się lepszy.

# Podstawowe elementy teorii

## Macierzowa postać równania regresji

Rozważamy równanie:
$$Y_i = \beta_0 + \beta_1 X_{i1} + ... + \beta_n X_{in} + \epsilon_i$$
Można je zapisać w postaci macierzowej:
$$Y = \textbf X \beta + \epsilon$$
gdzie:

- $Y = (Y_1, Y_2, ... Y_n)^T$,

- $\beta = (\beta_0, \beta_1, ..., \beta_n)^T$,

- $\epsilon = (\epsilon_1, \epsilon_2,..., \epsilon_n)^T$,

oraz: $$ \textbf X = \left(\begin{array}{cccc}
   1  & X_{11} &...& X_{1n}\\
    1 & X_{21} &...& X_{2n}\\
    ... & ...&...&...\\
    1 & X_{n1} & ... & X_{nn}
\end{array}\right) $$


## Przedział ufności dla kombinacji liniowej $c' \beta$.

Odchylenie standardowe $c' \hat \beta$ obliczymy korzystając ze wzoru:
$$c' \hat \beta \pm t_c s(c' \hat \beta)$$
  
gdzie:
  
- $\hat \beta = (\hat \beta_0, ..., \hat \beta_n)^T$,

- $c$ to wektor liczb,
  
- $t_c$, czyli kwantyl rzędu $1 - \frac{\alpha}{2}$ z rozkładu studenta z n-p stopniami swobody,
  
- $s(c' \hat \beta)$ to odchylenie standardowe, które obliczamy ze wzoru: 
$$s^2(c' \hat \beta) = s^2 c' (\textbf X' \textbf X)^{-1} c$$
  
\newpage
## Testowanie dotyczące wektora parametrów $\beta$.

Chcemy testować istotność dowolnej kombinacji liniowej elementów wektora $\beta$.
\newline
Mamy wektor c = ($c_0, ..., c_{p-1})' \in R^p$ oraz stałą d $\in R$.
Testujemy hipotezę zerową postaci:
$$H_0: c' \beta - d = 0$$
Przeciwko alternatywie:
$$H_1: c' \beta - d \neq 0$$
Statystyka testowa ma postać: $$T = \frac{c' \hat \beta - d}{s (c' \hat \beta)}$$
gdzie $s^2(c' \hat \beta) = s^2 c' (\textbf X' \textbf X)^{-1}c$.

Przy założeniu prawdziwości $H_0$, statystyka T ma rozkład studenta z n-p stopniami swobody. Zatem będziemy odrzucać $H_0$ na poziomie istotności $\alpha$, gdy |T| > $t_c$, gdzie $t_c = t^*(1 - \frac{\alpha}{2}, n-p)$, czyli jest kwantylem rzędu 
\newline
1 - $\frac{\alpha}{2}$ z rozkładu studenta z n-p stopniami swobody.

## Kryterium AIC

Kryterium AIC bada dopasowanie modelu do danych wraz z uwzględnieniem liczby zmiennych objaśniających użytych w modelu (im więcej, tym gorzej, ponieważ chcemy, aby model był możliwie jak najprostszy). Im mniejszą wartość przyjmuje statystyka AIC, tym model jest lepszy.

$$AIC = nlog \left(\frac{SSE}{n} \right) + 2k$$

gdzie:

- $SSE = \sum_{i=1}^{n}(Y_i - \hat Y_i)^2$,

- k to liczba zmiennych objaśniających użytych w modelu,

- n to wymiar zmiennej Y.

\newpage
# Zadanie 1: Wpływ korelacji

## a) Wygenerowanie macierzy $\textbf X$ i wektora Y

W podpunkcie a) jesteśmy proszeni o wygenerowanie macierzy $\textbf X_{100 \times 2}$ takiej, że jej wiersze są niezależnymi wektorami losowymi z rozkładu N($0, \frac{\Sigma}{100}$), gdzie
$$\Sigma = \left(\begin{array}{cc}
   1  & 0.9\\
    0.9 & 1
\end{array}\right)$$
```{r echo=F, warning=F}
library(MASS)
set.seed(8)
#generujemy X
X = matrix(0, nrow=100, ncol=2)
sigma = matrix(c(1, 0.9, 0.9, 1), nrow=2)
sigma=sigma/100
X = mvrnorm(100, mu=c(0, 0), Sigma=sigma)
```

Następnie należy wygenerować wektor $Y = \beta_1 X_1 + \epsilon$, gdzie:

- $\beta_1=3$,

- $X_1$ to pierwsza kolumna macierzy $\textbf X$,

- $\epsilon$ ~ N(0, I).

```{r echo=F}
beta_1 = 3
X_1 = X[,1]
Y = beta_1*X_1 + rnorm(100, 0, 1)
```

## b) t-test i 95% PU dla $\beta_1$

W tym podpunkcie należy przeprowadzić t-test na poziomie istotności $\alpha=0.05$ oraz wyznaczyć 95% przedział ufności dla $\beta_1$ w dwóch przypadkach:

- przy użyciu modelu prostej regresji liniowej: $Y = \beta_0 + \beta_1 X_1 + \epsilon$,

- używając modelu z dwiema zmiennymi objaśnianymi: $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$, gdzie $X_2$ to druga kolumna macierzy $\textbf X$ wygenerowanej w poprzednim podpunkcie.

### Model $Y = \beta_0 + \beta_1 X_1 + \epsilon$.

```{r echo=F}
model = lm(Y~X_1)
#95% PU
lewy = confint(model, level=0.95)[2]
lewy = round(lewy, 4)
prawy = confint(model, level=0.95)[4]
prawy = round(prawy, 4)
```

95% Przedział ufności dla $\beta_1$ jest postaci: [`r lewy`; `r prawy`].

```{r echo=F}
t = summary(model)$coefficients[6]
t = round(t, 4)
tc = qt(0.975, length(X_1)-2)
tc = round(tc, 4)

b1_hat = summary(model)$coefficients[2]
b1_hat = round(b1_hat, 4)
```

Statystyka testowa T ma wartość `r t`, natomiast kwantyl rzędu 0.975 z `r length(X_1)-2` stopniami swobody ma wartość `r tc`. Widzimy, że T> $t_c$, zatem odrzucamy $H_0$.

### Model $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$.

```{r echo=F}
X_2 = X[,2]
model2 = lm(Y~X_1 + X_2)
lewy2 = confint(model2, level=0.95)[2]
lewy2 = round(lewy2, 4)
prawy2 = confint(model2, level=0.95)[5]
prawy2 = round(prawy2, 4)
```

W tym modelu, 95% przedział ufności dla $\beta_1$ jest postaci: [`r lewy2`; `r prawy2`].

```{r echo=F}
t2 = summary(model2)$coefficients[8]
t2 = round(t2, 4)
tc2 = qt(0.975, length(X_1)-3)
tc2 = round(tc2, 4)

b1_hat2 = summary(model2)$coefficients[2]
b1_hat2 = round(b1_hat2, 4)
```

Wartość statystyki T ma wartość `r t2`, natomiast kwantyl $t_c$ = `r tc2`. Widzimy, że statystyka T przyjmuje mniejszą wartość niż w przypadku wyżej rozważanego modelu, jednak nie zmienia to faktu, że i tak odrzucamy $H_0$, ponieważ T > $t_c$.

Porównajmy wyniki dla obu modeli w tabeli:

Model  | $Y = \beta_0 + \beta_1 X_1 + \epsilon$ | $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$
----------------|---------------|----------------------
$\hat \beta_1$ | `r b1_hat` | `r b1_hat2`
95% PU | [`r lewy`; `r prawy`] | [`r lewy2`; `r prawy2`]
Długość PU | `r prawy - lewy` | `r prawy2 - lewy2`
Wartość statystyki T | `r t` | `r t2`
Wartość kwantyla $t_c$ | `r tc` | `r tc2`
Czy odrzucamy $H_0$? | TAK | TAK

W obu przypadkach z 95% prawdopodobieństwem odrzucamy $H_0$ mówiącą, że $\beta_1=0$.
Dla modelu z dwoma zmiennymi objaśniającymi widzimy, że przedział ufności dla $\beta_1$ osiąga większą długość niż dla modelu z jedną zmienną, a także wartość $\hat \beta_1$ jest większa.

## c) Odchylenie standardowe $\beta_1$ i moc identyfikacji $X_1$

Odchylenie standardowe $\beta_1$ obliczymy korzystając ze wzoru:

$$s^2(c' \hat \beta) = s^2 c' (\textbf X' \textbf X)^{-1} c$$

dla wektora $c' = (0,1)$ w przypadku pierwszego modelu lub $c' = (0, 1, 0)$ w przypadku drugiego modelu.

Z racji, że interesuje nas teoretyczna wartość odchylenia standardowego, we wzorze zamiast $s^2$ użyjemy znane nam $\sigma^2=1$.

```{r echo=F}
b0_hat = summary(model)$coefficients[1]
c = c(0, 1)

s2 = 1
X_matrix = matrix(data=1, nrow=100, ncol=2)
X_matrix[,2] = X_1
s2_beta1 = s2* t(c) %*% solve(t(X_matrix) %*% X_matrix) %*% c
s_beta1 = sqrt(s2_beta1)
s_beta1 = round(as.numeric(s_beta1), 4)

###########################
b0_hat2 = summary(model2)$coefficients[1]
b2_hat2 = summary(model2)$coefficients[3]
c = c(0, 1, 0)

s2 = 1
X_matrix2 = matrix(1, nrow=100, ncol=3)
X_matrix2[,2] = X_1
X_matrix2[,3] = X_2
s2_beta1_2 = s2* t(c) %*% solve(t(X_matrix2) %*% X_matrix2) %*% c
s_beta1_2 = sqrt(s2_beta1_2)
s_beta1_2 = round(as.numeric(s_beta1_2), 4)
```

Moc identyfikacji $X_1$ to prawdopodobieństwo odrzucenia $H_0$ mówiącej, że $\beta_1 = 0$ wiedząc, że prawdziwa jest hipoteza alternatywna $H_1: \beta_1 = 3$.

Statystyka testowa T jest postaci: $$T = \frac{c' \hat \beta - d}{s (c' \hat \beta)}$$ dla d = 0 oraz tak dobranego wektora c, aby $c' \hat \beta = \hat \beta_1$.
Przy założeniu, że $\beta_1=3$, statystyka T ma niecentralny rozkład studenta z parametrem niecentralności $\delta = \frac{\beta_1}{\sigma(\hat \beta_1)}$.
\newline
$\sigma(\hat \beta_1)$ liczymy ze wzoru: $$\sigma^2(\hat \beta_1) = \frac{\sigma^2}{\sum_{i=1}^{n} (X_i - \bar X)^2}$$

Moc testu to $P_{\beta_1 = 3}(|T| > t_c)$, gdzie $t_c$ to odpowiedni kwantyl.

```{r echo=F}
b1 = 3
n = length(Y)
delta = b1/s_beta1
tc = qt(0.975, n-2)
P = pt((-1)*tc, n-2, delta) + 1 - pt(tc, n-2, delta)
P = round(P, 4)

########## Drugi model

delta = b1/s_beta1_2
tc = qt(0.975, n-3)
P2 = pt((-1)*tc, n-3, delta) + 1 - pt(tc, n-3, delta)
P2 = round(P2, 4)
```

Model | $Y = \beta_0 + \beta_1 X_1 + \epsilon$ | $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$
---------|-----------------|-----------
$s(\hat \beta_1)$ | `r s_beta1` | `r s_beta1_2`
Moc identyfikacji $X_1$ | `r P`  | `r P2`

Odchylenie standardowe estymatora $\beta_1$ jest większe dla modelu z dwoma zmiennymi. Jest to spójne z wnioskiem z poprzedniego podpunktu mówiącym, że przedział ufności dla $\beta_1$ w tym modelu jest większy. Moc identyfikacji dla modelu z jedną zmienną objasniającą jest wysoka, natomiast dla drugiego modelu znacznie mniejsza. Może wynikać to z faktu, że zmienne $X_1$ i $X_2$ są skorelowane, zatem można podejrzewać, że da się przybliżyć model $Y = \beta_0 + \beta_1 X_1 + \epsilon$ zastępując $X_1$ zmienną $X_2$, a także zmieniając wartości parametrów $\beta_0$ i $\beta_1$.

## d) Estymacja wartości parametrów z poprzedniego podpunktu.

Estymowaną wartość mocy obliczamy poprzez zsumowanie liczby zdarzeń, w których odrzucamy $H_0$, a następnie podzielenie wyniku przez liczbę wszystkich doświadczeń, czyli 1000.

Odchylenie standardowe estymujemy poprzez obliczenie odchylenia standarowego dla każdego z 1000 wygenerowanych zbiorów danych, a następnie obliczenie ich średniej arytmetycznej.

```{r echo=F}
#macierz epsilonów: każdy wiersz to wektor epsilonów
Epsilony = matrix(0, nrow=10^3, ncol=10^2)
for(i in 1:10^3){
  Epsilony[i, ] = rnorm(10^2, 0, 1)
}

#macierz Y
Y_model1 = matrix(0, nrow=10^3, ncol=10^2)
for(i in 1:10^3){
  Y_model1[i,] = 3*X_1 + Epsilony[i,]
}

#tworzymy dwie ramki danych do przechowania informacji
zad1d_model1 = matrix(0, ncol=3)
zad1d_model1 = as.data.frame(zad1d_model1)
colnames(zad1d_model1) = c("est beta_1", "test ist", "s(beta_1)")

zad1d_model2 = matrix(0, ncol=3)
zad1d_model2 = as.data.frame(zad1d_model1)
colnames(zad1d_model2) = c("est beta_1", "test ist", "s(beta_1)")

#Przypisujemy wartości:
for(i in 1:10^3){
  
  #jesteśmy w wierszu nr i
  model = lm(Y_model1[i,] ~ X_1)
  zad1d_model1[i, 1] = round( summary(model)$coefficients[2], 4 )
  
  #sprawdzamy czy p-wartość < 0.05
  if(summary(model)$coefficients[8]< 0.05) zad1d_model1[i, 2] = 1 #odrzucamy
  else zad1d_model1[i, 2] = 0 #nie odrzucamy
  
  
  zad1d_model1[i, 3] = round( summary(model)$coefficients[4], 4 )
  
  
  #DRUGA RAMKA DANYCH:
  model2 = lm(Y_model1[i,] ~ X_1+X_2)
  zad1d_model2[i, 1] = round( summary(model2)$coefficients[2], 4 )
  
  #sprawdzamy czy p-wartość < 0.05
  if(summary(model2)$coefficients[11]< 0.05) zad1d_model2[i, 2] = 1 #odrzucamy
  else zad1d_model2[i, 2] = 0 #nie odrzucamy
  
  zad1d_model2[i, 3] = round( summary(model2)$coefficients[5], 4 )

}
```

Zobaczmy wyniki dla modelu $Y = \beta_0 + \beta_1 X_1 + \epsilon$ w tabeli:

Badana wielkość | Teoretyczna wartość | Estymowana wartość
---------|----------------------------|--------------------
$\hat \beta_1$ | 3 | `r round( mean(zad1d_model1[,1]), 4 )`
$s(\hat \beta_1)$ | `r s_beta1` | `r round( mean(zad1d_model1[,3]), 4 )`
Moc | `r P` | `r round( sum(zad1d_model1[,2])/1000, 4)`

\newpage
Wyniki dla modelu $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$:

Badana wielkość | Teoretyczna wartość | Estymowana wartość
---------|----------------------------|--------------------
$\hat \beta_1$ | 3 | `r round( mean(zad1d_model2[,1]), 4 )`
$s(\hat \beta_1)$ | `r s_beta1_2` | `r round( mean(zad1d_model2[,3]), 4 )`
Moc | `r P2` | `r round( sum(zad1d_model2[,2])/1000, 4)`

Dla obu modeli możemy wyciągnąć wniosek, że estymowane wartości dobrze przybliżają teoretyczne.

\newpage
# Zadanie 2: wpływ wymiaru.

## a) Wygenerowanie macierzy X i wektora Y

W tym zadaniu należy wygenerować macierz $X_{1000 \times 950}$ tak, że jej elementy są niezależnymi zmiennymi losowymi z rozkładu $N(0, \sigma=0.1)$.
Wektor zmiennej odpowiedzi wyraża się wzorem: $$Y = X \beta + \epsilon$$
gdzie $\beta = (3, 3, 3, 3, 3, 0, ..., 0)^T$.

```{r echo=F}
n.sample <- 1000
n.col <- 950
n.beta <- 5
alpha <- 0.05

sd <- 0.1
sd.eps <- 0.1

X.matrix <- matrix(rnorm(n.sample*n.col,
                         mean = 0,
                         sd = sd),
                   nrow = n.sample,
                   ncol = n.col)
colnames(X.matrix) <- paste0("X", 1:n.col)

beta.vec <- c(rep(3, times = n.beta), 
              rep(0, times = n.col-n.beta))

Y <- apply(X.matrix, 1, function(x){
                      sum(x*beta.vec) + rnorm(1, sd = sd.eps)
                    })
```

## b) Analiza różnych postaci modelu i wybranie najlepszego z użyciem kryterium AIC.

Model jest zbudowany przy użyciu pierwszych $k$ kolumn macierzy dla $k \in \{1, 2, 5, 10, 50, 100, 500, 950\}$.
\newline
Dla każdego modelu obliczamy następujące wielkości:

- SSE,

- MSE,

- AIC,

- p-wartości dla dwóch pierwszych zmiennych objaśniających,

- liczbę fałszywych odkryć.

Poprzez fałszywe odkrycie rozumiemy odrzucenie $H_0$, gdy jest prawdziwa, albo nieodrzucenie $H_0$, gdy jest fałszywa.

```{r echo=F}
possible.cols <- c(1,2,5,10,50,100,500,950)

result.info <- data.frame(`Selected.Cols` = possible.cols,
                          `SSE` = 0,
                          `MSE` = 0,
                          `AIC` = 0,
                          `p.val.first` = 0,
                          `p.val.second` = 0,
                          `False.Discoveries` = 0)


for(col in possible.cols){
  #0. Pomocnicza zmienna - wiersz w result.info
  col.itr <- which(possible.cols == col)
  #1. Wybierz odpowiednie dane
  X.tmp <- as.data.frame(X.matrix[,1:col], ncol = col)
  colnames(X.tmp) <- paste0("X", 1:col)
  data <- cbind(Y, X.tmp)
  #2. Stworz model - pamietaj o automatyzacji formuly
  formula.txt <- paste0("Y ~ -1 + ", paste0(colnames(X.tmp), collapse = "+"))
  model <- lm(formula = as.formula(formula.txt), data = data)
  
  #3. Wrzuc info do result.info
  model.summary <- summary(model)
  
  result.info[col.itr, "SSE"] <- sum(model.summary$residuals^2)
  result.info[col.itr, "MSE"] <- result.info[col.itr, "SSE"]/(n.sample - col)
  result.info[col.itr, "AIC"] <- n.sample*log(result.info[col.itr, "SSE"]/n.sample) + 2*col
  result.info[col.itr, "p.val.first"] <- model.summary$coefficients[1,"Pr(>|t|)"]
  if(col == 1) {
    result.info[col.itr, "p.val.second"] <- NA
  } else {
    result.info[col.itr, "p.val.second"] <- model.summary$coefficients[2,"Pr(>|t|)"]
  }
  n.reject.true.regressors <- sum(model.summary$coefficients[1:min(col, 5),"Pr(>|t|)"] > alpha)
  n.non.reject.false.regressors <- 0
  if(col > 5){
    n.non.reject.false.regressors <- sum(model.summary$coefficients[6:col,"Pr(>|t|)"] < alpha)   
  }
  result.info[col.itr, "False.Discoveries"] <- n.reject.true.regressors + n.non.reject.false.regressors
}
```

| k | SSE | MSE |  AIC | $p_1$ | $p_2$ | Fałszywe odkrycia|
|--|-----|-----|---------|-----------|-----------|--------------|
|1 | `r round( result.info$SSE[1], 4)` | `r round( result.info$MSE[1], 4)` | `r round(result.info$AIC[1], 4)` | `r round( result.info$p.val.first[1], 54)` | NA | `r result.info[1,7]`|
|2 | `r round( result.info$SSE[2], 4)` | `r round( result.info$MSE[2], 4)` | `r round(result.info$AIC[2], 4)` | `r round( result.info$p.val.first[2], 67)` | `r round( result.info[2, 6], 80)` | `r result.info[2,7]`|
|5 | `r round( result.info$SSE[3], 4)` | `r round( result.info$MSE[3], 4)` | `r round(result.info$AIC[3], 4)` | `r result.info$p.val.first[3]` | `r result.info[3, 6]` | `r result.info[3,7]`|
|10 | `r round( result.info$SSE[4], 4)` | `r round( result.info$MSE[4], 4)` | `r round(result.info$AIC[4], 4)` | `r result.info$p.val.first[4]` |`r result.info[4, 6]`  | `r result.info[4,7]`|
|50 | `r round( result.info$SSE[5], 4)` | `r round( result.info$MSE[5], 4)` | `r round(result.info$AIC[5], 4)` | `r result.info$p.val.first[5]` |`r result.info[5, 6]`  | `r result.info[5,7]`|
|100 | `r round( result.info$SSE[6], 4)` | `r round( result.info$MSE[6], 4)` | `r round(result.info$AIC[6], 4)` | `r result.info$p.val.first[6]` |`r result.info[6, 6]`  | `r result.info[6,7]`|
|500 | `r round( result.info$SSE[7], 4)` | `r round( result.info$MSE[7], 4)` | `r round(result.info$AIC[7], 4)` | `r round(result.info$p.val.first[7], 240)` |`r round( result.info[7, 6], 263)`  | `r result.info[7,7]`|
|950 | `r round( result.info$SSE[8], 4)` | `r round( result.info$MSE[8], 4)` | `r round(result.info$AIC[8], 4)` | `r round( result.info$p.val.first[8], 26)` |`r round( result.info[8, 6], 31)`  | `r result.info[8,7]`|

Widzimy, że wraz ze wzrostem ilości zmiennych (wartości k), wartość SSE oraz MSE maleje. Bardzo dużą różnicę widać między k=2 a k=5. P-wartości dla każdej wartości k są bardzo małe i pozwalają na odrzucenie hipotez mówiących, że $\beta_1=0$ oraz $\beta_2=0$.
Liczba fałszywych odkryć rośnie od k=50. Dla mniejszych k jest równa 0.

Na podstawie kryterium AIC należy wybrać model, dla którego wartość AIC jest najmniejsza. Analizując powyższą tabelę możemy zauważyć, że minimalną wartość AIC równą `r round( min(result.info$AIC), 4)` osiąga model z liczbą zmiennych równą k = `r possible.cols[which(result.info$AIC == min(result.info$AIC))]`.

\newpage
## d) Powtórzenie zadania 2b z dodatkiem mocy identyfikacji $X_1$ i $X_2$.

W tym podpunkcie należy powtórzyć polecenia z zadania 2b 1000 razy. Wyniki ponownie zostaną przedstawione w tabeli, jednak każda wartość będzie średnią arytmetyczną poszczególnych wyników (np. wartość AIC dla k=1 będzie obliczana 1000 razy, zatem w tabeli znajdzie się średnia arytmetyczna otrzymanych wyników).

```{r echo=F}
possible.cols <- c(1,2,5,10,50,100,500,950)
min.aic = numeric(500)

Info = array(0, dim=c(length(possible.cols), 9, 500))

for(j in 1:500){

Y <- apply(X.matrix, 1, function(x){
                      sum(x*beta.vec) + rnorm(1, sd = sd.eps)
                    })
  
result.info = Info[,,j]

result.info[,1] = possible.cols

    
    for(col in possible.cols){
      #0. Pomocnicza zmienna - wiersz w result.info
      col.itr <- which(possible.cols == col)
      #1. Wybierz odpowiednie dane
      X.tmp <- as.data.frame(X.matrix[,1:col], ncol = col)
      colnames(X.tmp) <- paste0("X", 1:col)
      data <- cbind(Y, X.tmp)
      #2. Stworz model - pamietaj o automatyzacji formuly
      formula.txt <- paste0("Y ~ -1 + ", paste0(colnames(X.tmp), collapse = "+"))
      model <- lm(formula = as.formula(formula.txt), data = data)
  
      #3. Wrzuc info do result.info
      model.summary <- summary(model)
  
      result.info[col.itr, 2] <- sum(model.summary$residuals^2)
      result.info[col.itr, 3] <- result.info[col.itr, 2]/(n.sample - col)
      result.info[col.itr, 4] <- n.sample*log(result.info[col.itr, 2]/n.sample)       + 2*col
      result.info[col.itr, 5] <- model.summary$coefficients[1,"Pr(>|t|)"]
      if(col == 1) {
        result.info[col.itr, 6] <- NA
      } else {
        result.info[col.itr, 6] <- model.summary$coefficients[2,"Pr(>|t|)"]
      }
      n.reject.true.regressors <- sum(model.summary$coefficients[1:min(col,5),"Pr(>|t|)"] > alpha)
  n.non.reject.false.regressors <- 0
     if(col > 5){
       n.non.reject.false.regressors <-    sum(model.summary$coefficients[6:col,"Pr(>|t|)"] < alpha)   
    }
    result.info[col.itr, 7] <- n.reject.true.regressors + n.non.reject.false.regressors
    
    if(model.summary$coefficients[1, "Pr(>|t|)"] < alpha){
      result.info[col.itr, 8] = 1
    } else result.info[col.itr, 8] = 0
    
    result.info[col.itr, 9] = NA
    if(col > 1){
      
      if(model.summary$coefficients[2, "Pr(>|t|)"] < alpha){
      result.info[col.itr, 9] = 1
    } else result.info[col.itr, 9] = 0
    
    }
    
    }

min.aic[j] = which(result.info[,4] == min(result.info[,4]))

Info[,,j] = result.info
}

Mean.info = data.frame(`Selected.Cols` = possible.cols,
                          `SSE` = 0,
                          `MSE` = 0,
                          `AIC` = 0,
                          `p.val.first` = 0,
                          `p.val.second` = 0,
                          `False.Discoveries` = 0,
                          `Moc.X1` = 0,
                          `Moc.X2` = 0)

for(iter in 1:length(possible.cols)){
  
  for(kols in 1:9){
    if(iter == 1 & kols == 6){
    Mean.info[iter, kols] = NA
    }
    else {
      if(iter ==1 & kols == 9) Mean.info[iter, kols] = NA
      else Mean.info[iter, kols] = mean(Info[iter, kols, ])
    }
  }
}
```

| k | SSE | MSE |  AIC | $p_1$ | $p_2$ | Fałszywe odkrycia|
|--|-----|-----|---------|-----------|-----------|--------------|
|1 | `r round( Mean.info$SSE[1], 4)` | `r round( Mean.info$MSE[1], 4)` | `r round(Mean.info$AIC[1], 4)` | `r round( Mean.info$p.val.first[1], 54)` | NA | `r Mean.info[1,7]`|
|2 | `r round( Mean.info$SSE[2], 4)` | `r round( Mean.info$MSE[2], 4)` | `r round(Mean.info$AIC[2], 4)` | `r round( Mean.info$p.val.first[2], 64)` | `r round( Mean.info[2, 6], 76)` | `r Mean.info[2,7]`|
|5 | `r round( Mean.info$SSE[3], 4)` | `r round( Mean.info$MSE[3], 4)` | `r round(Mean.info$AIC[3], 4)` | `r Mean.info$p.val.first[3]` | `r Mean.info[3, 6]` | `r Mean.info[3,7]`|
|10 | `r round( Mean.info$SSE[4], 4)` | `r round( Mean.info$MSE[4], 4)` | `r round(Mean.info$AIC[4], 4)` | `r Mean.info$p.val.first[4]` |`r Mean.info[4, 6]`  | `r Mean.info[4,7]`|
|50 | `r round( Mean.info$SSE[5], 4)` | `r round( Mean.info$MSE[5], 4)` | `r round(Mean.info$AIC[5], 4)` | `r Mean.info$p.val.first[5]` |`r Mean.info[5, 6]`  | `r Mean.info[5,7]`|
|100 | `r round( Mean.info$SSE[6], 4)` | `r round( Mean.info$MSE[6], 4)` | `r round(Mean.info$AIC[6], 4)` | `r Mean.info$p.val.first[6]` |`r Mean.info[6, 6]`  | `r Mean.info[6,7]`|
|500 | `r round( Mean.info$SSE[7], 4)` | `r round( Mean.info$MSE[7], 4)` | `r round(Mean.info$AIC[7], 4)` | `r round(Mean.info$p.val.first[7], 236)` |`r round( Mean.info[7, 6], 247)`  | `r Mean.info[7,7]`|
|950 | `r round( Mean.info$SSE[8], 4)` | `r round( Mean.info$MSE[8], 4)` | `r round(Mean.info$AIC[8], 4)` | `r round( Mean.info$p.val.first[8], 26)` |`r round( Mean.info[8, 6], 29)`  | `r Mean.info[8,7]`|

Z powyższej tabeli możemy wyciągnąć podobne wnioski, co dla tabeli z zadania 2b.
Należy zwrócić uwagę, że już dla k=10 pojawiają się pojedyncze fałszywe odkrycia. Wartość SSE również maleje wraz ze wzrostem wartości k. Wartość MSE znacznie maleje między k=2 a k=5, po czym utrzymuje się na stałym poziomie. Jedynie dla k=950 jest ciut większa, jednak różnica pojawia się dopiero na 4. miejscu po przecinku, zatem decydujemy się na pominięcie tego wniosku.

Średni rozmiar modelu wybranego przez AIC to `r possible.cols[round( mean(min.aic), 0)]`. W zadaniu 2b było to 950. Widzimy, że wynik jest taki sam.

W tym zadaniu należy jeszcze obliczyć moc identyfikacji $X_1$ i $X_2$, którą rozumiemy jako prawdopodobieństwo odrzucenia $H_0: \beta_1=0$, pod warunkiem, że $\beta_1 = 3$. Analogicznie dla $X_2$.

Patrząc na to, jak bardzo małe są p-wartości w powyższej tabeli, można przypuszczać, że moce identyfikacji będą równe 1 lub prawie równe 1.

Liczba kolumn | Moc identyfikacji $X_1$ | Moc identyfikacji $X_2$
-------|--------------|--------------
1 | `r Mean.info$Moc.X1[1]` | `r Mean.info$Moc.X2[1]`
2 | `r Mean.info$Moc.X1[2]` | `r Mean.info$Moc.X2[2]`
5 | `r Mean.info$Moc.X1[3]` | `r Mean.info$Moc.X2[3]`
10 | `r Mean.info$Moc.X1[4]` | `r Mean.info$Moc.X2[4]`
50 | `r Mean.info$Moc.X1[5]` | `r Mean.info$Moc.X2[5]`
100 | `r Mean.info$Moc.X1[6]` | `r Mean.info$Moc.X2[6]`
500 | `r Mean.info$Moc.X1[7]` | `r Mean.info$Moc.X2[7]`
950 | `r Mean.info$Moc.X1[8]` | `r Mean.info$Moc.X2[8]`

Wyniki nas nie zaskoczyły: moce identyfikacji są równe 1.